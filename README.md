This repository contains the foundation of a local-first desktop application designed to become an AI-powered assistant in future versions.
The current version intentionally focuses on user interface, application structure, and code clarity, rather than AI inference itself.

The goal of this project is to build a clean, extensible, and maintainable desktop application that can later integrate local language models and optional speech features without architectural changes.

Project Focus

This version of the project prioritizes:

UI and user experience design

Clean and readable Python code

Modular and scalable structure

Local execution without external services

AI-related features are not included yet by design.

Current Capabilities

Desktop application built with PyQt5

Dark-themed, modern chat-style interface

Scrollable conversation area

Message input and display system

Local-only execution (no cloud, no API usage)

This version serves as a UI and architecture prototype.

Planned Direction

Future versions of this project may include:

Local LLM integration using llama.cpp

Optional GPU acceleration

Offline speech-to-text support

Modular AI backend with interchangeable models

Fully offline AI assistant experience

These features are intentionally excluded from the current release to keep the repository clean and free from licensing or hardware constraints.

Notes

No AI models are included in this repository

No user data is sent anywhere

Conversations remain on the local device

Licensing will be defined in future versions

If this project caught your interest, feel free to leave a star. :)




